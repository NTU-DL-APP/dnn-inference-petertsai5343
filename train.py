import tensorflow as tf
import numpy as np
import os
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

def create_optimized_fashion_mnist_model():
    """å»ºç«‹ä¸¦è¨“ç·´ä¸€å€‹å„ªåŒ–çš„Fashion-MNIST DNNåˆ†é¡æ¨¡å‹"""
    
    print("ğŸ”„ æ­£åœ¨è¼‰å…¥Fashion-MNISTè³‡æ–™é›†...")
    
    # è¼‰å…¥Fashion-MNISTè³‡æ–™é›†
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()
    
    # é€²éšè³‡æ–™é è™•ç†
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    
    # è³‡æ–™æ¨™æº–åŒ– (å¯é¸ï¼Œä½†é€šå¸¸æœ‰åŠ©æ–¼DNNè¨“ç·´)
    mean = np.mean(x_train)
    std = np.std(x_train)
    x_train = (x_train - mean) / std
    x_test = (x_test - mean) / std
    
    print(f"è¨“ç·´è³‡æ–™å½¢ç‹€: {x_train.shape}")
    print(f"æ¸¬è©¦è³‡æ–™å½¢ç‹€: {x_test.shape}")
    print(f"è³‡æ–™æ¨™æº–åŒ– - å¹³å‡å€¼: {mean:.4f}, æ¨™æº–å·®: {std:.4f}")
    
    # å»ºç«‹å„ªåŒ–çš„æ¨¡å‹æ¶æ§‹
    print("\nğŸ—ï¸ æ­£åœ¨å»ºç«‹å„ªåŒ–æ¨¡å‹...")
    model = tf.keras.Sequential([
        # è¼¸å…¥å±¤
        tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten'),
        
        # ç¬¬ä¸€éš±è—å±¤ - æ›´å¤§çš„ç¥ç¶“å…ƒæ•¸é‡
        tf.keras.layers.Dense(512, name='dense_1'),
        tf.keras.layers.BatchNormalization(name='bn_1'),
        tf.keras.layers.Activation('relu', name='relu_1'),
        tf.keras.layers.Dropout(0.3, name='dropout_1'),
        
        # ç¬¬äºŒéš±è—å±¤
        tf.keras.layers.Dense(256, name='dense_2'),
        tf.keras.layers.BatchNormalization(name='bn_2'),
        tf.keras.layers.Activation('relu', name='relu_2'),
        tf.keras.layers.Dropout(0.4, name='dropout_2'),
        
        # ç¬¬ä¸‰éš±è—å±¤
        tf.keras.layers.Dense(128, name='dense_3'),
        tf.keras.layers.BatchNormalization(name='bn_3'),
        tf.keras.layers.Activation('relu', name='relu_3'),
        tf.keras.layers.Dropout(0.4, name='dropout_3'),
        
        # ç¬¬å››éš±è—å±¤
        tf.keras.layers.Dense(64, name='dense_4'),
        tf.keras.layers.BatchNormalization(name='bn_4'),
        tf.keras.layers.Activation('relu', name='relu_4'),
        tf.keras.layers.Dropout(0.3, name='dropout_4'),
        
        # è¼¸å‡ºå±¤
        tf.keras.layers.Dense(10, activation='softmax', name='output',
                             kernel_regularizer=l2(0.001))
    ])
    
    # ä½¿ç”¨å„ªåŒ–çš„ç·¨è­¯åƒæ•¸
    optimizer = Adam(
        learning_rate=0.001,
        beta_1=0.9,
        beta_2=0.999,
        epsilon=1e-07
    )
    
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # é¡¯ç¤ºæ¨¡å‹æ¶æ§‹
    print("\nğŸ“‹ å„ªåŒ–æ¨¡å‹æ¶æ§‹:")
    model.summary()
    
    # è¨­ç½®å›èª¿å‡½æ•¸
    callbacks = [
        # æ—©åœï¼šé©—è­‰æº–ç¢ºç‡ä¸å†æå‡æ™‚åœæ­¢è¨“ç·´
        EarlyStopping(
            monitor='val_accuracy',
            patience=15,
            restore_best_weights=True,
            verbose=1
        ),
        
        # å­¸ç¿’ç‡èª¿åº¦ï¼šé©—è­‰æå¤±ä¸å†ä¸‹é™æ™‚é™ä½å­¸ç¿’ç‡
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=8,
            min_lr=1e-7,
            verbose=1
        ),
        
        # æ¨¡å‹æª¢æŸ¥é»ï¼šå„²å­˜æœ€ä½³æ¨¡å‹
        ModelCheckpoint(
            'best_fashion_mnist.h5',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    # è¨“ç·´æ¨¡å‹
    print("\nğŸš€ é–‹å§‹è¨“ç·´å„ªåŒ–æ¨¡å‹...")
    print("ä½¿ç”¨çš„å„ªåŒ–æŠ€è¡“:")
    print("- æ›´æ·±çš„ç¶²è·¯æ¶æ§‹ (4å€‹éš±è—å±¤)")
    print("- Batch Normalization")
    print("- Dropout æ­£å‰‡åŒ–")
    print("- L2 æ¬Šé‡æ­£å‰‡åŒ–")
    print("- å­¸ç¿’ç‡èª¿åº¦")
    print("- æ—©åœæ©Ÿåˆ¶")
    print("- è³‡æ–™æ¨™æº–åŒ–")
    
    history = model.fit(
        x_train, y_train,
        epochs=50,  # å¢åŠ æœ€å¤§è¨“ç·´è¼ªæ•¸ï¼Œä¾è³´æ—©åœæ©Ÿåˆ¶
        batch_size=64,  # è¼ƒå°çš„æ‰¹æ¬¡å¤§å°é€šå¸¸æœ‰åŠ©æ–¼æ³›åŒ–
        validation_split=0.15,  # å¢åŠ é©—è­‰é›†æ¯”ä¾‹
        callbacks=callbacks,
        verbose=1
    )
    
    # è¼‰å…¥æœ€ä½³æ¨¡å‹é€²è¡Œè©•ä¼°
    model = tf.keras.models.load_model('best_fashion_mnist.h5')
    
    # è©•ä¼°æ¨¡å‹
    print("\nğŸ“Š è©•ä¼°æœ€ä½³æ¨¡å‹æ€§èƒ½...")
    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
    print(f"æœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {test_accuracy:.4f}")
    
    # å„²å­˜æœ€çµ‚æ¨¡å‹
    model_path = 'fashion_mnist.h5'
    model.save(model_path)
    print(f"\nğŸ’¾ æ¨¡å‹å·²å„²å­˜è‡³: {model_path}")
    
    # é¡¯ç¤ºè¨“ç·´æ­·å²
    print("\nğŸ“ˆ è¨“ç·´æ­·å²æ‘˜è¦:")
    if len(history.history['accuracy']) > 0:
        max_train_acc = max(history.history['accuracy'])
        max_val_acc = max(history.history['val_accuracy'])
        print(f"æœ€é«˜è¨“ç·´æº–ç¢ºç‡: {max_train_acc:.4f}")
        print(f"æœ€é«˜é©—è­‰æº–ç¢ºç‡: {max_val_acc:.4f}")
        print(f"æœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {test_accuracy:.4f}")
    
    return model, test_accuracy, history

def create_alternative_model():
    """å»ºç«‹å¦ä¸€ç¨®æ¶æ§‹çš„å„ªåŒ–æ¨¡å‹ï¼ˆå¦‚æœç¬¬ä¸€ç¨®æ•ˆæœä¸ä½³ï¼‰"""
    print("\nğŸ”„ å˜—è©¦æ›¿ä»£æ¶æ§‹...")
    
    model = tf.keras.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten'),
        
        # ä½¿ç”¨æ›´å¯¬çš„ç¶²è·¯
        tf.keras.layers.Dense(1024, activation='relu', name='dense_1',
                             kernel_regularizer=l2(0.0001)),
        tf.keras.layers.Dropout(0.5, name='dropout_1'),
        
        tf.keras.layers.Dense(512, activation='relu', name='dense_2',
                             kernel_regularizer=l2(0.0001)),
        tf.keras.layers.Dropout(0.5, name='dropout_2'),
        
        tf.keras.layers.Dense(256, activation='relu', name='dense_3',
                             kernel_regularizer=l2(0.0001)),
        tf.keras.layers.Dropout(0.4, name='dropout_3'),
        
        tf.keras.layers.Dense(10, activation='softmax', name='output')
    ])
    
    return model

def setup_data_folder():
    """è¨­ç½®è³‡æ–™å¤¾çµæ§‹"""
    os.makedirs('model', exist_ok=True)
    os.makedirs('data/fashion', exist_ok=True)
    print("ğŸ“ è³‡æ–™å¤¾çµæ§‹å·²å»ºç«‹")

if __name__ == "__main__":
    print("ğŸ¯ Fashion-MNIST å„ªåŒ–æ¨¡å‹è¨“ç·´ç¨‹å¼")
    print("=" * 60)
    
    # è¨­ç½®GPUè¨˜æ†¶é«”æˆé•·ï¼ˆå¦‚æœæœ‰GPUï¼‰
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print("ğŸ”§ GPUè¨˜æ†¶é«”æˆé•·å·²å•Ÿç”¨")
        except RuntimeError as e:
            print(f"GPUè¨­ç½®è­¦å‘Š: {e}")
    
    # è¨­ç½®è³‡æ–™å¤¾
    setup_data_folder()
    
    # æª¢æŸ¥æ˜¯å¦å·²æœ‰æ¨¡å‹
    if os.path.exists('fashion_mnist.h5'):
        choice = input("å·²å­˜åœ¨ fashion_mnist.h5 æª”æ¡ˆï¼Œè¦é‡æ–°è¨“ç·´å—ï¼Ÿ(y/n): ").lower()
        if choice != 'y':
            print("ä½¿ç”¨ç¾æœ‰æ¨¡å‹æª”æ¡ˆ")
            exit()
    
    try:
        # å»ºç«‹å’Œè¨“ç·´å„ªåŒ–æ¨¡å‹
        model, accuracy, history = create_optimized_fashion_mnist_model()
        
        print("\nâœ… å„ªåŒ–æ¨¡å‹è¨“ç·´å®Œæˆï¼")
        print(f"æœ€çµ‚æ¸¬è©¦æº–ç¢ºç‡: {accuracy:.4f}")
        
        # å¦‚æœæº–ç¢ºç‡ä¸å¤ é«˜ï¼Œçµ¦å‡ºå»ºè­°
        if accuracy < 0.90:
            print("\nğŸ’¡ æº–ç¢ºç‡æå‡å»ºè­°:")
            print("- å¯ä»¥å˜—è©¦èª¿æ•´Dropoutæ¯”ç‡")
            print("- å¢åŠ æˆ–æ¸›å°‘éš±è—å±¤ç¥ç¶“å…ƒæ•¸é‡")
            print("- èª¿æ•´å­¸ç¿’ç‡")
            print("- å¢åŠ è¨“ç·´è¼ªæ•¸")
        else:
            print(f"\nğŸ‰ æ­å–œï¼é”åˆ°äº† {accuracy:.1%} çš„é«˜æº–ç¢ºç‡ï¼")
        
        print("\nğŸ“ ä¸‹ä¸€æ­¥:")
        print("1. åŸ·è¡Œ 'python convert_model.py' è½‰æ›æ¨¡å‹")
        print("2. åŸ·è¡Œ 'python model_test.py' æ¸¬è©¦æ¨ç†")
        
    except Exception as e:
        print(f"âŒ å»ºç«‹æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        print("è«‹æª¢æŸ¥æ˜¯å¦å·²å®‰è£æ‰€éœ€å¥—ä»¶:")
        print("pip install tensorflow numpy matplotlib")